{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29ebc97-0158-410f-b4a0-63eda2d5def7",
   "metadata": {},
   "source": [
    "## Project: Scrapping Premier League Incoming Transfer data between 2000 and 2024 from transfermarkt.co.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8bc3a1-be1d-4b0c-a656-63d22bdd2d6f",
   "metadata": {},
   "source": [
    "Libraries: requests (to fetch web pages) , BeautifulSoup (to navigate and extract data from requested web pages) , pandas (to put extracted data into dataframe and save locally)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4de17f-52c0-49ee-ac75-982e7b734c17",
   "metadata": {},
   "source": [
    "This is the first part of a three project series where I will ultimately analyse the performances of all incoming players to find which ones had the best debut seasons. This comparison will be done by their whoscored ratings from the end of the season. Let's get started here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683763f2-442e-474c-b906-5e085322d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346e08eb-753b-4d59-845c-6dcb9c5a53a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for the request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a27d57-f4ff-4635-86e9-58df8bf84f0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "We use Headers to mimic a web browser when making requests. This helps in avoiding issues like being blocked by the website due to bot-like behavior. After all, bots are just a bunch of codes, just like this. This particular User Agent mimics a chrome browser being used on Linux OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54c106b-a030-4d6c-b1f7-e81eee7ac60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list to store player data\n",
    "all_player_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2180a9-8964-4f7f-b8c0-d06cfdf63b3b",
   "metadata": {},
   "source": [
    "To store all the player and transfer data we extract, we create an empty list like the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46d3492-1e56-4647-94e9-53faccb4ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract player information for incoming transfers only\n",
    "def extract_player_data(team_name, team_div, season_year):\n",
    "    transfer_table = team_div.find_all('table')\n",
    "\n",
    "    # Use the first table for incoming transfers (transfer_type = 0)\n",
    "    if transfer_table and len(transfer_table) >= 2:\n",
    "        headers = [th.text.strip() for th in transfer_table[0].find('thead').find_all('th')]  # First table is for 'In' transfers\n",
    "        rows = transfer_table[0].find('tbody').find_all('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            # Replace '-' with None (null) in each cell value\n",
    "            data = [td.text.strip() if td.text.strip() != \"-\" else None for td in row.find_all('td')]\n",
    "            player_data = [team_name, 'In', season_year] + data\n",
    "            all_player_data.append(player_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3bb974-e027-4c2f-91da-190af96da357",
   "metadata": {},
   "source": [
    "We had to inspect the element of the webpage to understand the structure before writing this code so don't worry if it is a bit confusing. Basically, this function extracts player data for incoming transfers,*'In'*, from a given team's transfer table.\n",
    "It finds the relevant table, extracts headers and rows, then processes each row to extract player details and transfer information.\n",
    "Each player's data is stored in **all_player_data** as a list containing team name, transfer direction, season year, and player details. \n",
    "Initially, I extracted transfers in both directions but limited it to just In's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb641e15-3750-43bb-998d-b2d34b6aff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each season from 2000 to 2023\n",
    "for season_year in range(2000, 2024):\n",
    "    # URL for both summer and winter transfers\n",
    "    base_url = f\"https://www.transfermarkt.co.uk/premier-league/transfers/wettbewerb/GB1/plus/?saison_id={season_year}&s_w=&leihe=1&intern=0&intern=1\"\n",
    "\n",
    "    # Request the page and set encoding\n",
    "    pageTree = requests.get(base_url, headers=headers)\n",
    "    pageTree.encoding = 'utf-8'  # Ensure UTF-8 encoding for the request\n",
    "    soup = BeautifulSoup(pageTree.content, 'lxml', from_encoding='utf-8')  # Use 'lxml' parser with UTF-8 encoding\n",
    "\n",
    "    # Extract teams from the page and filter out empty strings\n",
    "    teams = soup.select('h2.content-box-headline a[href*=\"/transfers/verein/\"]')\n",
    "    teams_list = [(team.text.strip(), team) for team in teams if team.text.strip()]\n",
    "\n",
    "    # Iterate through each team and extract player information for incoming transfers only\n",
    "    for team_name, team_anchor in teams_list:\n",
    "        \n",
    "        # Using the previously selected 'team_anchor' directly instead of searching for it again and only process if the URL contains '/transfers/verein/'\n",
    "        if '/transfers/verein/' in team_anchor['href']:\n",
    "            team_div = team_anchor.find_parent('div', class_='box')\n",
    "\n",
    "            # If not found, try finding a different div class (like 'responsive-table')\n",
    "            if not team_div:\n",
    "                print(f\"Warning: No div with class 'box' found for {team_name}. Trying 'responsive-table'.\")\n",
    "                team_div = team_anchor.find_parent('div', class_='responsive-table')\n",
    "\n",
    "            # Check if the team_div is found\n",
    "            if team_div:\n",
    "                # Extract incoming transfers only (transfer_type=0)\n",
    "                extract_player_data(team_name, team_div, season_year)\n",
    "            else:\n",
    "                print(f\"Warning: No div found for {team_name} after searching multiple classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e17aa4-f8da-4fe5-847d-0a1e6e4f2aff",
   "metadata": {},
   "source": [
    "Here lies the heavy lifter. Since the transfer information we need is from different pages on the transfermarkt site, we need a way to automatically open each page. Luckily, the only thing that changes with each url is the **season year**, we can easily iterate through each page by changing the part of the url that changes. We tried a couple of methods and ran into different errors which is why the *soup.select* to ensure that the \\<a> anchor has a \\<href> which contains part of the transfers url. \n",
    "The next step is to add the team names and anchor to **teams_list** then check through the parent div and extract the transfer information. If there's any issue with finding a div element of any team, a warning message will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e86a165-e246-4059-8b57-48b52b7fde9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Team Transfer Direction  Year  \\\n",
      "0                 Leeds United                 In  2000   \n",
      "1                 Leeds United                 In  2000   \n",
      "2                 Leeds United                 In  2000   \n",
      "3                 Leeds United                 In  2000   \n",
      "4                 Leeds United                 In  2000   \n",
      "...                        ...                ...   ...   \n",
      "10219  Wolverhampton Wanderers                 In  2023   \n",
      "10220  Wolverhampton Wanderers                 In  2023   \n",
      "10221  Wolverhampton Wanderers                 In  2023   \n",
      "10222  Wolverhampton Wanderers                 In  2023   \n",
      "10223  Wolverhampton Wanderers                 In  2023   \n",
      "\n",
      "                          Player Age Nationality            Position  \\\n",
      "0      Rio FerdinandR. Ferdinand  22                     Centre-Back   \n",
      "1      Olivier DacourtO. Dacourt  25              Defensive Midfield   \n",
      "2           Mark VidukaM. Viduka  24                  Centre-Forward   \n",
      "3        Dominic MatteoD. Matteo  26                       Left-Back   \n",
      "4            Jacob BurnsJ. Burns  22              Defensive Midfield   \n",
      "...                          ...  ..         ...                 ...   \n",
      "10219      Bruno JordãoB. Jordão  24              Defensive Midfield   \n",
      "10220   Chem CampbellC. Campbell  21              Attacking Midfield   \n",
      "10221    Gonçalo GuedesG. Guedes  26                     Left Winger   \n",
      "10222     Bendegúz BollaB. Bolla  23                      Right-Back   \n",
      "10223    Gonçalo GuedesG. Guedes  27                     Left Winger   \n",
      "\n",
      "      Short Position Market Value Left Team Left Team Flag  \\\n",
      "0                 CB         None                 West Ham   \n",
      "1                 DM         None                     Lens   \n",
      "2                 CF         None                   Celtic   \n",
      "3                 LB         None                Liverpool   \n",
      "4                 DM         None             Parra. Power   \n",
      "...              ...          ...       ...            ...   \n",
      "10219             DM       €1.30m              Santa Clara   \n",
      "10220             AM        €900k                  Wycombe   \n",
      "10221             LW      €23.00m                  Benfica   \n",
      "10222             RB       €2.70m             Grasshoppers   \n",
      "10223             LW      €18.00m                  Benfica   \n",
      "\n",
      "                           Fee  \n",
      "0                      €26.00m  \n",
      "1                      €10.50m  \n",
      "2                       €9.15m  \n",
      "3                       €7.13m  \n",
      "4                        €375k  \n",
      "...                        ...  \n",
      "10219  End of loanJun 30, 2023  \n",
      "10220  End of loanMay 31, 2024  \n",
      "10221  End of loanJun 30, 2023  \n",
      "10222  End of loanJun 30, 2023  \n",
      "10223  End of loanJan 18, 2024  \n",
      "\n",
      "[10224 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the collected player data\n",
    "columns = ['Team', 'Transfer Direction', 'Year', 'Player', 'Age', 'Nationality', 'Position', 'Short Position',\n",
    "           'Market Value', 'Left Team', 'Left Team Flag', 'Fee']\n",
    "df = pd.DataFrame(all_player_data, columns=columns)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Export the DataFrame to a CSV file with UTF-8 encoding, treating None as empty strings in the CSV\n",
    "df.to_csv('20Years_PL_transfers.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f48cf0-b6d5-4ce0-9cd8-668e0825390c",
   "metadata": {},
   "source": [
    "Assigning the appripriate column names, creating and viweing and saving the dataframe is the final step in this process. I hope you had some fun doing this. See you soon!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
